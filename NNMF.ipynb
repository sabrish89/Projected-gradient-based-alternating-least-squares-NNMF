{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import clock\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import sys\n",
    "\n",
    "def is_pos_def(V):\n",
    "    '''Check to see if matrix is at worst psd\n",
    "       Returns: True if pd or psd else False\n",
    "    '''\n",
    "    return np.all(np.linalg.eigvals(V) >= 0)\n",
    "\n",
    "def multiplicative_nnmf(V,bas_card,p_iter=5000,random_state=0,verbose=False,adhere=False):\n",
    "    '''Proposed by Lee and Seung (2000). \n",
    "       Guarantee   :  Adherence to Theorem 1 - strict adherence to Karush Kuhn Tucker condition of feasibility - (3).1 >see options\n",
    "                      Preference indicated in (8)\n",
    "       Returns     :  W and H\n",
    "       Complexity  :  O(max(n,m)r^2) per iteration- assumed V,W,H are not sparse - as per (8)\n",
    "       Mandatories :  bas_card - basis set cardinality r < min(m,n)\n",
    "       Options     :  random_state - seed value - Default:0\n",
    "                      iterations p_iter - update stopping criterion - Default:5000 iterations\n",
    "                      adhere for guarantee 1 / autocorrect - Default:False\n",
    "                      verbose for iteration information - Default:False\n",
    "       Eg Usage    :  >rnd_V = np.array([np.random.uniform(1,12,23).tolist() for i in range(23)]) #need not be square!\n",
    "                      >W,H = multiplicative_nnmf(rnd_V,bas_card=7,adhere=True,verbose=True)\n",
    "                      >np.matmul(W,H)\n",
    "       Issues      :  Lossy at high ratios\n",
    "    '''\n",
    "    \n",
    "    if type(V) != np.ndarray:\n",
    "        V = np.asarray(V)\n",
    "    \n",
    "    #Check adherence\n",
    "    if adhere == True:\n",
    "        rows = np.where(~V.any(axis=1))[0]\n",
    "        cols = np.where(~V.any(axis=0))[0]\n",
    "        if rows.size != 0 or cols.size != 0:\n",
    "            V = np.delete(np.delete(V,rows,0),cols,1)\n",
    "            print(\"\\rViolations found and corrected...\")\n",
    "    \n",
    "    #Read shape of input\n",
    "    n,m = V.shape[0],V.shape[1]\n",
    "    \n",
    "    #Initialize W and H\n",
    "    np.random.RandomState(random_state)\n",
    "    r = bas_card\n",
    "    W = np.array([np.random.uniform(0.1,1,r).tolist() for i in range(n)])\n",
    "    H = np.array([np.random.uniform(0.1,1,m).tolist() for i in range(r)])\n",
    "    \n",
    "    #Update\n",
    "    for i in range(p_iter):\n",
    "        num = np.matmul(V,np.transpose(H))\n",
    "        den = np.matmul(W,np.matmul(H,np.transpose(H)))\n",
    "        for j in range(n):\n",
    "            W[j,:] *= num[j,:]/den[j,:]\n",
    "        num = np.matmul(np.transpose(W),V)\n",
    "        den = np.matmul(np.matmul(np.transpose(W),W),H)\n",
    "        for k in range(r):\n",
    "            H[k,:] *= num[k,:]/den[k,:]\n",
    "        err = round(np.sum(np.square(np.subtract(V,np.matmul(W,H))/V))/2,2)\n",
    "        if verbose == True:\n",
    "            sys.stdout.write(\"\\rCurrent Normalized SSError: %.2f\" % err)\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "    return W,H\n",
    "\n",
    "def shepherds_descent_nnmf(V,bas_card,alpha=0.001,p_iter=5000,random_state=0,verbose=False):\n",
    "    '''Proposed by Shepherd (2004). A projected gradient approach.\n",
    "       Guarantee   :  GLB 0; convergence not guaranteed by Theorem 2 due to no explicit upper bound\n",
    "                      Manner of descent updation via max(0,.) in each iteration k, implies NN W and H\n",
    "       Returns     :  W and H\n",
    "       Complexity  :  O(nmr) per iteration- assumed V,W,H are not sparse\n",
    "       Mandatories :  bas_card - basis set cardinality/compression criteria r < min(m,n)\n",
    "       Options     :  random_state - seed value - Default:0\n",
    "                      step size alpha - Default:0.001\n",
    "                      iterations p_iter - update stopping criterion - Default:5000 iterations\n",
    "                      verbose - show iteration information - Default:False\n",
    "       Eg usage    :  >rnd_V = np.array([np.random.uniform(1,23,12).tolist() for i in range(8)])\n",
    "                      >W,H = shepherds_descent_nnmf(rnd_V,bas_card=5,verbose=True)\n",
    "                      >np.matmul(W,H)\n",
    "       Issues      :  May get stuck in local minima. Can be seen when multiplicative_nnmf\n",
    "                      gives a significantly lower compression-reconstruction error.\n",
    "    '''\n",
    "    \n",
    "    if type(V) != np.ndarray:\n",
    "        V = np.asarray(V)\n",
    "        \n",
    "    #Read shape of input\n",
    "    n,m = V.shape[0],V.shape[1]\n",
    "    \n",
    "    #Initialize W and H\n",
    "    np.random.RandomState(random_state)\n",
    "    r = bas_card\n",
    "    W = np.array([np.random.uniform(0,1,r).tolist() for i in range(n)])\n",
    "    H = np.array([np.random.uniform(0,1,m).tolist() for i in range(r)])\n",
    "    \n",
    "    #Update via unconstrained gradient descent\n",
    "    for k in range(p_iter):\n",
    "        grad_W = np.matmul(np.subtract(np.matmul(W,H),V),np.transpose(H))\n",
    "        grad_H = np.matmul(np.transpose(W),np.subtract(np.matmul(W,H),V))\n",
    "        W = np.maximum(np.subtract(W,np.multiply(alpha,grad_W)),np.zeros([n,r]))\n",
    "        H = np.maximum(np.subtract(H,np.multiply(alpha,grad_H)),np.zeros([r,m]))\n",
    "        err = round(np.sum(np.square(np.subtract(V,np.matmul(W,H))/V))/2,2)\n",
    "        if verbose == True:\n",
    "            sys.stdout.write(\"\\rCurrent Normalized SSError: %.2f\" % err)\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    return W,H\n",
    "\n",
    "def newton_block_nnmf(V,bas_card,p_iter=100,sub_iter=50,alpha=0.001,random_state=0,verbose=False,safe=False):\n",
    "    '''Proposed by Chu (2005). *WIP* *unstable*\n",
    "       Guarantee   :  GLB 0; Significantly faster convergence *unstable!*\n",
    "                      Newtons method of *!optimization* root approximation to solve subproblems => approach saddle\n",
    "       Returns     :  W and H\n",
    "       Complexity  :  O(2nmrp) per iteration- assumed V,W,H are not sparse\n",
    "       Mandatories :  bas_card - basis set cardinality/compression criteria r < min(m,n)\n",
    "       Options     :  random_state - seed value - Default:0\n",
    "                      sub_iter - sub-problem solving iterations for each block - 1 => regular descent\n",
    "                      > 1 => approximate iterative block coordinate descent.\n",
    "                      iterations p_iter - update stopping criterion - Default:100 iterations\n",
    "                      verbose - show iteration information - Default:False\n",
    "                      safe - safe mode - return least local minima found during descent - Default:False\n",
    "       Issues      :  May not be always optimal and frequently overshoots minima - try enabling safe\n",
    "                      mode to get the local minima\n",
    "       Edit        :  1. Using Netwon's root approximation Order 1 instead Order 2\n",
    "    '''\n",
    "    \n",
    "    if type(V) != np.ndarray:\n",
    "        V = np.asarray(V)\n",
    "        \n",
    "    #Read shape of input\n",
    "    n,m = V.shape[0],V.shape[1]\n",
    "    \n",
    "    #Initialize W and H\n",
    "    np.random.RandomState(random_state)\n",
    "    r = bas_card\n",
    "    W = np.array([np.random.uniform(0,1,r).tolist() for i in range(n)])\n",
    "    #W = np.zeros([n,r])\n",
    "    H = np.array([np.random.uniform(0,1,m).tolist() for i in range(r)])\n",
    "    #H = np.zeros([r,m])\n",
    "    if safe == True:\n",
    "        err_1 = np.inf\n",
    "    \n",
    "    #Update via block gradient descent\n",
    "    for k in range(p_iter):\n",
    "        for j in range(sub_iter):\n",
    "            grad_W  = np.matmul(np.subtract(np.matmul(W,H),V),np.transpose(H))\n",
    "            #grad_2W = np.matmul(H,np.transpose(H)) #square so can invert!\n",
    "            grad_H  = np.matmul(np.transpose(W),np.subtract(np.matmul(W,H),V))\n",
    "            #grad_2H = np.matmul(np.transpose(W),W) #square so can invert!\n",
    "            #if is_pos_def(np.invert(grad_2W.astype(np.int))):\n",
    "                #W = np.maximum(np.subtract(W,np.multiply(alpha,np.matmul(grad_W,np.invert(grad_2W.astype(np.int))))),np.zeros([n,r]))\n",
    "            #else:\n",
    "                #W = np.maximum(np.add(W,np.multiply(alpha,np.matmul(grad_W,np.invert(grad_2W.astype(np.int))))),np.zeros([n,r]))\n",
    "            #print(np.invert(grad_W.astype(np.int)))\n",
    "            W = np.maximum(np.add(W,np.multiply(alpha,np.invert(grad_W.astype(np.int)))),np.zeros([n,r]))\n",
    "            err = round(np.sum(np.square(np.subtract(V,np.matmul(W,H))/V))/2,2)\n",
    "            if verbose == True:\n",
    "                sys.stdout.write(\"\\rCurrent Normalized SSError: %.2f\" % err)\n",
    "                sys.stdout.flush()\n",
    "            if safe == True:\n",
    "                if err < err_1:\n",
    "                    err_1 = err\n",
    "                    W_1 = W\n",
    "                    H_1 = H\n",
    "        for k in range(sub_iter):\n",
    "            grad_W  = np.matmul(np.subtract(np.matmul(W,H),V),np.transpose(H))\n",
    "            #grad_2W = np.matmul(H,np.transpose(H)) #square so can invert!\n",
    "            grad_H  = np.matmul(np.transpose(W),np.subtract(np.matmul(W,H),V))\n",
    "            #grad_2H = np.matmul(np.transpose(W),W) #square so can invert!\n",
    "            #if is_pos_def(np.invert(grad_2W.astype(np.int))):\n",
    "                #H = np.maximum(np.subtract(H,np.multiply(alpha,np.matmul(np.invert(grad_2H.astype(np.int)),grad_H))),np.zeros([r,m]))\n",
    "            #else:\n",
    "                #H = np.maximum(np.add(H,np.multiply(alpha,np.matmul(np.invert(grad_2H.astype(np.int)),grad_H))),np.zeros([r,m]))\n",
    "            #print(np.invert(grad_H.astype(np.int)))\n",
    "            H = np.maximum(np.add(H,np.multiply(alpha,np.invert(grad_H.astype(np.int)),grad_H)),np.zeros([r,m]))\n",
    "            err = round(np.sum(np.square(np.subtract(V,np.matmul(W,H))/V))/2,2)\n",
    "            if verbose == True:\n",
    "                sys.stdout.write(\"\\rCurrent Normalized SSError: %.2f\" % err)\n",
    "                sys.stdout.flush()\n",
    "            if safe == True:\n",
    "                if err < err_1:\n",
    "                    err_1 = err\n",
    "                    W_1 = W\n",
    "                    H_1 = H\n",
    "    if safe == True and verbose == True:\n",
    "        print(\"\\rMinimum Normalized SSError:\",err_1)\n",
    "        return W_1,H_1\n",
    "    elif safe == True:\n",
    "        return W_1,H_1\n",
    "    else:\n",
    "        return W,H\n",
    "\n",
    "def step_search(H,W,V,verbose=False):\n",
    "    '''Implements the step size search to optimize cost decrease per sub-step\n",
    "       Input  : H  - matrix to optimize\n",
    "                W  - block held constant\n",
    "                V  - input matrix\n",
    "       Returns: optimized H\n",
    "    '''\n",
    "    \n",
    "    #Initialize alpha,beta\n",
    "    a = 1\n",
    "    b = 0.1\n",
    "    \n",
    "    #Conversion buffers\n",
    "    if type(W) != np.ndarray:\n",
    "        W = np.array(W)\n",
    "    if type(H) != np.ndarray:\n",
    "        H = np.array(H)\n",
    "    if type(V) != np.ndarray:\n",
    "        V = np.array(V)\n",
    "    \n",
    "    #Calculate W'V and W'W\n",
    "    WW = np.matmul(np.transpose(W),W) #O(r^2n)\n",
    "    try:\n",
    "        WV = np.matmul(np.transpose(W),V) #O(rmn)\n",
    "    except:\n",
    "        WV = np.matmul(V,np.transpose(W)) #O(rmn)\n",
    "    \n",
    "    path = False\n",
    "    try:\n",
    "        grad_H = np.subtract(np.matmul(WW,H),WV)\n",
    "    except:\n",
    "        grad_H = np.subtract(np.matmul(H,WW),WV)\n",
    "    #Search for alpha\n",
    "    #print('\\nStart New')\n",
    "    for j in range(20):\n",
    "        #Compute new H\n",
    "        H_n = np.maximum(np.subtract(H,np.multiply(a,grad_H)),np.zeros(list(H.shape)))\n",
    "        diff_H = np.subtract(H_n,H)\n",
    "        #Calculate condition of decrease in Cost for alpha\n",
    "        d = np.subtract(H_n,H)\n",
    "        gradd = np.sum(np.multiply(grad_H,d))\n",
    "        dQd = np.sum(np.multiply(d,np.matmul(WW,d)))\n",
    "        suff_decr = 0.99*gradd + 0.5*dQd < 0\n",
    "        #Fix direction of iteration\n",
    "        #print(0.99*gradd + 0.5*dQd)\n",
    "        if j == 0: #Fix path to avoid convoluted exit conditions\n",
    "            decr_alpha = not suff_decr\n",
    "            H_p = H\n",
    "        if decr_alpha: #do we go the path of decreasing learnng rate?\n",
    "            if suff_decr: #do we satisfy sufficiency condition? \n",
    "                if verbose == True:\n",
    "                    err = round(np.sum(np.square(np.subtract(V,np.matmul(W,H_n))/V))/2,2)\n",
    "                    sys.stdout.write(\"\\rCurrent Normalized SSError: %.2f\" % err)\n",
    "                    sys.stdout.flush()\n",
    "                H = H_n\n",
    "                break\n",
    "            else:\n",
    "                a = a*b\n",
    "        else:\n",
    "            if not suff_decr or np.allclose(H_n,H_p): #right condition is to exit when sufficient convergence cannot be achieved\n",
    "                if verbose == True:\n",
    "                    err = round(np.sum(np.square(np.subtract(V,np.matmul(W,H_p))/V))/2,2)\n",
    "                    sys.stdout.write(\"\\rCurrent Normalized SSError: %.2f\" % err)\n",
    "                    sys.stdout.flush()\n",
    "                H = H_p\n",
    "                break\n",
    "            else:\n",
    "                a = a/b\n",
    "                H_p = H_n\n",
    "    return H\n",
    "\n",
    "def pgals_nnmf(V,bas_card,p_iter=50,sub_iter=100,random_state=0,verbose=False):\n",
    "    '''Projected Gradient based alternating NN least squares block descent as per paper (4.1)\n",
    "       Complexity  :  p_iter*(O(nmr) + sub_iter*O(tmr^2+tnr^2)); t=20 as per paper\n",
    "       Guarantees  :  Asymptotic/Limiting Covergence to minima saddle as per Theorem 2 for 2 block descent\n",
    "       Mandatories :  bas_card - basis set cardinality/compression criteria r < min(m,n)\n",
    "       Options     :  random_state - seed value - Default:0\n",
    "                      sub_iter - sub-problem solving iterations for each block - 1 => regular descent\n",
    "                      > 1 => approximate iterative block coordinate descent - Default:100 sub-iterations per p_iter\n",
    "                      iterations p_iter - update stopping criterion - Default:50 iterations\n",
    "                      verbose - show iteration information - Default:False\n",
    "       Benefits    :  self-adjusted learning at each sub-step to maximize cost reduction\n",
    "    '''\n",
    "    \n",
    "    if type(V) != np.ndarray:\n",
    "        V = np.asarray(V)\n",
    "        \n",
    "    #Read shape of input\n",
    "    n,m = V.shape[0],V.shape[1]\n",
    "    \n",
    "    #Initialize W and H\n",
    "    np.random.RandomState(random_state)\n",
    "    r = bas_card\n",
    "    W = np.array([np.random.uniform(0,1,r).tolist() for i in range(n)])\n",
    "    H = np.array([np.random.uniform(0,1,m).tolist() for i in range(r)])\n",
    "    \n",
    "    #Update via block descent\n",
    "    for k in range(p_iter):\n",
    "        #print('W')\n",
    "        for i in range(sub_iter):\n",
    "            W = step_search(np.transpose(W),np.transpose(H),np.transpose(V),verbose=verbose)\n",
    "            W = np.transpose(W)\n",
    "        #print('\\nH')\n",
    "        for j in range(sub_iter):\n",
    "            H = step_search(H,W,V,verbose=verbose)\n",
    "    return W,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_V = np.array([np.random.uniform(0,23,12).tolist() for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Normalized SSError: 12.3736"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13.22906688, 12.27085873, 15.49220192, 10.70200395,  6.37459773,\n",
       "         8.14471545,  8.95097905, 14.24657871, 13.44272388, 18.37806974,\n",
       "        14.26191189,  4.77713329],\n",
       "       [10.24450048, 15.34300995,  4.44440535, 11.9650178 , 12.93573084,\n",
       "         4.40548438,  2.28872522,  4.63207284, 12.36468414,  7.03169328,\n",
       "         3.34459766, 22.1573894 ],\n",
       "       [14.99976387,  0.        , 14.13480808, 12.50825982,  8.6738422 ,\n",
       "        13.1747374 , 18.15829068,  8.05445747,  8.54261555, 19.64200748,\n",
       "        10.23872389,  3.96793762],\n",
       "       [ 4.22572157,  7.53180438, 17.63878835,  5.424312  , 10.27689805,\n",
       "        22.48967712, 21.71946919,  4.71233045, 15.62968191,  5.63232291,\n",
       "        18.14729452, 15.05688094],\n",
       "       [17.95429387,  5.73519362, 10.62536297, 14.99574291,  9.21951461,\n",
       "         6.09422106, 10.05131724, 10.67474605,  8.96593771, 21.48235646,\n",
       "         6.72542265,  6.13896244],\n",
       "       [17.57211507, 13.01868914,  7.77208434,  4.22492269, 10.54867324,\n",
       "        18.05442528, 20.48867206, 19.66358214, 15.18639834, 11.43604602,\n",
       "        14.96992339, 15.7764337 ],\n",
       "       [17.18036266,  5.71481864,  0.        ,  3.39613638,  7.15041558,\n",
       "         9.66959827, 14.06215083, 15.82845435,  6.87132351, 10.6285282 ,\n",
       "         5.64114234,  8.88046188],\n",
       "       [12.20410205, 19.60447499, 17.90969509,  7.74472996,  3.74632067,\n",
       "         7.33448339,  5.94811256, 20.46271414, 17.11268666, 18.03069527,\n",
       "        19.62616968,  3.00725046]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W,H = shepherds_descent_nnmf(rnd_V,bas_card=5,verbose=True)\n",
    "np.matmul(W,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Normalized SSError: 12.1240"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13.51338466, 12.40942932, 15.31506063, 10.46871232,  6.63494181,\n",
       "         8.14854964,  9.08816121, 14.29122673, 13.30303886, 18.35181441,\n",
       "        14.19647963,  4.54727958],\n",
       "       [10.01942755, 15.76769444,  4.66766293, 12.21555219, 13.20680441,\n",
       "         4.36255067,  2.59764537,  4.71049206, 12.09683137,  6.82156002,\n",
       "         3.12095183, 21.76298324],\n",
       "       [15.0839374 ,  0.        , 14.36861996, 12.3424739 ,  8.73704113,\n",
       "        13.30228233, 18.76181913,  7.70349095,  8.08438567, 19.55464364,\n",
       "        10.45843295,  2.55545839],\n",
       "       [ 3.86809623,  8.12824788, 18.66610127,  5.38627728, 10.81809788,\n",
       "        22.34692923, 21.71142286,  4.15597063, 15.34290588,  5.59220287,\n",
       "        17.43859202, 14.97297018],\n",
       "       [18.56283458,  6.52745205,  9.59691762, 14.90758688,  9.36246308,\n",
       "         5.62851372,  9.86583481, 11.22537609,  8.79370274, 21.18267102,\n",
       "         6.71587078,  5.67654696],\n",
       "       [17.56879726, 12.08617707,  6.23216489,  3.19449855,  9.56537501,\n",
       "        18.22546004, 20.18591758, 21.13173402, 15.65745955, 11.13186461,\n",
       "        15.44995535, 16.67101918],\n",
       "       [16.41702359,  4.26081893,  0.78087045,  4.96379169,  7.13435715,\n",
       "         9.90332342, 13.82168385, 14.34698842,  7.48943839, 11.33545567,\n",
       "         6.29146363,  9.50874155],\n",
       "       [12.02780967, 19.39762076, 18.35324707,  7.57574431,  3.89276016,\n",
       "         7.32496523,  5.63864457, 20.10958792, 17.24383795, 18.27384272,\n",
       "        19.71688205,  3.04825623]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W,H = pgals_nnmf(rnd_V,bas_card=5,verbose=True)\n",
    "np.matmul(W,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Normalized SSError: 12.7276"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.35259043e+01, 1.24227780e+01, 1.54553647e+01, 1.04950135e+01,\n",
       "        6.56964284e+00, 8.13559277e+00, 9.05254307e+00, 1.41495740e+01,\n",
       "        1.32944410e+01, 1.83790671e+01, 1.42450662e+01, 4.48588527e+00],\n",
       "       [9.92564518e+00, 1.59444711e+01, 4.79406637e+00, 1.21937984e+01,\n",
       "        1.32860950e+01, 4.35546473e+00, 2.58932642e+00, 4.60287433e+00,\n",
       "        1.20238429e+01, 7.05423275e+00, 3.06268671e+00, 2.16542024e+01],\n",
       "       [1.52362571e+01, 1.80108935e-57, 1.43175972e+01, 1.22491834e+01,\n",
       "        8.83071458e+00, 1.33606361e+01, 1.87898170e+01, 7.72910415e+00,\n",
       "        8.04022847e+00, 1.93641549e+01, 1.06715988e+01, 2.34275888e+00],\n",
       "       [4.35816410e+00, 7.90231610e+00, 1.89378888e+01, 5.45488094e+00,\n",
       "        1.07586028e+01, 2.22637095e+01, 2.16889693e+01, 4.28197794e+00,\n",
       "        1.53554483e+01, 5.74433804e+00, 1.70643674e+01, 1.50794103e+01],\n",
       "       [1.86582292e+01, 6.68664846e+00, 9.12179128e+00, 1.46700244e+01,\n",
       "        9.47704473e+00, 5.77118406e+00, 1.00103441e+01, 1.14348633e+01,\n",
       "        8.72819915e+00, 2.10134774e+01, 6.99528123e+00, 5.60129396e+00],\n",
       "       [1.72400017e+01, 1.19755349e+01, 5.74374793e+00, 3.19262405e+00,\n",
       "        9.37173904e+00, 1.83366983e+01, 2.02045783e+01, 2.13756276e+01,\n",
       "        1.57988723e+01, 1.10359918e+01, 1.57165686e+01, 1.68015081e+01],\n",
       "       [1.62978235e+01, 4.16363825e+00, 3.61710532e-01, 5.51028971e+00,\n",
       "        7.38119456e+00, 9.75689239e+00, 1.37007386e+01, 1.41279350e+01,\n",
       "        7.41529485e+00, 1.15676497e+01, 6.34587812e+00, 9.47964308e+00],\n",
       "       [1.20891319e+01, 1.93445026e+01, 1.84336474e+01, 7.58770966e+00,\n",
       "        3.64615923e+00, 7.28457462e+00, 5.60203887e+00, 2.00544341e+01,\n",
       "        1.72784531e+01, 1.83561861e+01, 1.96296529e+01, 3.18574466e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W,H = multiplicative_nnmf(rnd_V,bas_card=5,verbose=True)\n",
    "np.matmul(W,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Normalized SSError: 12.3796"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13.13965555, 12.15086957, 15.25068965, 10.4694824 ,  6.0379281 ,\n",
       "         7.98694957,  8.71996052, 14.54279463, 13.35938446, 18.26918217,\n",
       "        14.32908646,  4.54806396],\n",
       "       [10.20320369, 15.43493503,  4.3217782 , 11.71630497, 12.89538481,\n",
       "         4.09821659,  2.40682328,  4.95414942, 12.08242439,  6.6740627 ,\n",
       "         3.07299638, 22.06991407],\n",
       "       [14.78627599,  0.        , 13.88314603, 12.05918553,  8.42551461,\n",
       "        12.79115669, 17.8000506 ,  8.93417955,  8.56257917, 19.50016051,\n",
       "        10.16040397,  4.13812653],\n",
       "       [ 4.20832805,  6.51315183, 17.21355707,  5.27986396, 10.21547489,\n",
       "        22.35703742, 21.60054681,  4.82598493, 15.61005155,  6.13145006,\n",
       "        17.93152897, 15.33116448],\n",
       "       [17.37600101,  5.30661306, 11.1669528 , 15.25625494,  9.35271436,\n",
       "         6.0863201 , 10.24549066, 10.38865015,  8.8376028 , 21.25519813,\n",
       "         6.56827762,  6.38527717],\n",
       "       [17.41663243, 13.08500763,  8.31838894,  4.09564978, 10.41954509,\n",
       "        18.11219156, 20.33983034, 18.97755811, 15.17376695, 11.37325167,\n",
       "        15.16907504, 15.11246177],\n",
       "       [17.73310945,  5.73910868,  0.        ,  3.52739957,  7.40136436,\n",
       "         9.54732788, 14.21191755, 15.34570915,  6.42866567, 10.59756166,\n",
       "         5.0761828 ,  8.46897515],\n",
       "       [12.35866912, 19.55136156, 17.45313673,  7.93401365,  3.70499273,\n",
       "         7.32677169,  5.64124062, 20.05827072, 17.10146604, 17.92587009,\n",
       "        19.54859899,  3.18980014]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W,H = newton_block_nnmf(rnd_V,bas_card=5,verbose=True)\n",
    "np.matmul(W,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.27304693, 12.6529049 , 14.39565645, 12.65550079,  2.50644045,\n",
       "         9.11051508,  8.83182354, 11.46981118, 16.65025458, 15.79717371,\n",
       "        14.69734402,  3.42358053],\n",
       "       [12.10508645, 17.17633431,  4.60849711, 10.61172763, 13.14780492,\n",
       "         4.71704934,  2.46736094,  2.46237329, 11.76201642,  7.14814846,\n",
       "         3.42479451, 21.22538504],\n",
       "       [18.56390363,  0.09601965, 13.92257974,  8.94437808,  8.32120717,\n",
       "        13.964711  , 18.17313256,  2.78208614,  7.80995048, 21.13515186,\n",
       "        11.63096583,  1.92014144],\n",
       "       [ 1.42920956,  7.62993003, 19.4030864 ,  6.57115518, 12.10970014,\n",
       "        21.9039962 , 22.39277788,  7.21087625, 14.41616965,  4.75713064,\n",
       "        16.26410043, 15.04213776],\n",
       "       [12.18051747,  2.08269448, 10.13398037, 18.39551909, 10.38169984,\n",
       "         4.2460275 ,  9.74409215, 17.53466117,  9.21707785, 21.54462749,\n",
       "         6.00212461,  7.81936373],\n",
       "       [16.72293514,  9.20176112,  3.47659751,  4.1524457 ,  6.91350557,\n",
       "        18.44415692, 18.59932498, 19.93125135, 18.50055716, 12.77625441,\n",
       "        18.58697344, 18.55500641],\n",
       "       [18.11804351,  8.39018831,  0.4934254 ,  3.53261919, 10.50909426,\n",
       "         9.70393756, 15.93327354, 15.45689698,  3.77762928,  9.05072239,\n",
       "         2.09524233,  6.81242893],\n",
       "       [11.25030968, 20.69149405, 19.40225496,  5.5039743 ,  6.35348696,\n",
       "         6.97975025,  6.16393213, 20.84294315, 14.6643757 , 19.27769457,\n",
       "        18.84893775,  2.87246659]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_V"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
